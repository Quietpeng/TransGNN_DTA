{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0efcb096",
   "metadata": {},
   "source": [
    "# TransGNN_DTA Drug-Target Affinity Prediction Model User Guide  \n",
    "> A drug-target affinity prediction model based on Transformer and GNN, supporting multi-dataset training and prediction.  \n",
    "> Author: Quietpeng ([GitHub](https://github.com/Quietpeng)), related papers have been published (please refer to the project README for citation).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe2b42",
   "metadata": {},
   "source": [
    "## I. Environment Setup and Project Initialization  \n",
    "### 1.1 Clone the Project Repository  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b93497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (skip if already cloned)  \n",
    "!git clone https://github.com/Quietpeng/TransGNN_DTA.git  \n",
    "%cd TransGNN_DTA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8daae",
   "metadata": {},
   "source": [
    "### 1.2 Create and Activate a Virtual Environment (Recommended Best Practice)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python virtual environment (based on Python 3.12)  \n",
    "!python -m venv transgnn_env  \n",
    "# Activate the environment (Linux/macOS)  \n",
    "!source transgnn_env/bin/activate  \n",
    "# For Windows: .\\transgnn_env\\Scripts\\activate  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1ad1e",
   "metadata": {},
   "source": [
    "### 1.3 Install Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies (install PyTorch and CUDA in advance based on hardware configuration)  \n",
    "!pip install -r requirements.txt  \n",
    "# Optional: Install background management tools (for remote training monitoring)  \n",
    "!sudo apt install screen -y && sudo apt update  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba5dad",
   "metadata": {},
   "source": [
    "## II. Model Training Workflow  \n",
    "### 2.1 Configuration Instructions  \n",
    "**Command-Line Configuration Information**  \n",
    "| Parameter Name       | Type    | Default Value   | Description                                                                 |  \n",
    "|----------------------|---------|-----------------|-----------------------------------------------------------------------------|  \n",
    "| `b`                  | int     | 32              | Training batch size, adjust according to GPU memory (e.g., 64 for 32GB GPU) |  \n",
    "| `epochs`             | int     | 200             | Maximum number of training epochs, used with early stopping                |  \n",
    "| `dataset`            | str     | `raw_davis`     | Dataset selection, supports `raw_davis`/`raw_kiba`/`benchmark_davis`, etc. |  \n",
    "| `lr`                 | float   | 5e-4            | Initial learning rate, dynamically adjusted with AdamW optimizer and scheduler |  \n",
    "| `model_config`       | str     | `config.json`   | Path to model configuration file, containing key parameters like embedding dimension and maximum sequence length |  \n",
    "\n",
    "**Hyperparameter Configuration File Path**: `config.json` (adjust `drug_max_seq` and `target_max_seq` according to the dataset in advance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4ff00",
   "metadata": {},
   "source": [
    "### 2.2 Quick Start Training (Recommended for Background Execution)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee53f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Start with default parameters (output results to result.log)  \n",
    "!python train_reg.py &> result.log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8312a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Start with specified parameters (example: use raw_kiba dataset, batch size 128)  \n",
    "!python train_reg.py --dataset raw_kiba --batchsize 128 --lr 1e-4 &> result.log  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32524135",
   "metadata": {},
   "source": [
    "**Notes**:  \n",
    "- Training is recommended to use a GPU (e.g., 32GB vGPU), as laptops may crash due to insufficient resources.  \n",
    "- Use the `screen` tool for background execution:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655959ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!screen -S transgnn_train  # Create a new session  \n",
    "  # After executing the training command, press Ctrl+A+D to exit the session  \n",
    "!screen -r transgnn_train   # Resume the session "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290ce98",
   "metadata": {},
   "source": [
    "### 2.3 Training Monitoring and Visualization  \n",
    "**Visualization Address**: http://localhost:6006 (local) or server public IP:6006 (firewall needs to be open)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard monitoring (default port 6006, install screen in advance)  \n",
    "!screen -dmS tensorboard bash -c 'tensorboard --logdir=log --host=0.0.0.0'  \n",
    "# For remote access, configure port forwarding: ssh -L 6006:localhost:6006 user@server_ip  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9159cec",
   "metadata": {},
   "source": [
    "## III. Model Prediction Workflow  \n",
    "### 3.1 Load Pretrained Model and Configuration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6284d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import json  \n",
    "from preprocess import drug_encoder, target_encoder  \n",
    "from double_towers import TransGNNModel  \n",
    "\n",
    "# Example data (drug SMILES and protein sequence)  \n",
    "DRUG_EXAMPLE = \"CC1=C(C=C(C=C1)NC2=NC=CC(=N2)N(C)C3=CC4=NN(C(=C4C=C3)C)C)S(=O)(=O)Cl\"  \n",
    "PROTEIN_EXAMPLE = \"MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDLIVRVGDEIRLLCTDP\"  \n",
    "\n",
    "# Paths to configuration file and model  \n",
    "MODEL_CONFIG_PATH = \"config.json\"  \n",
    "MODEL_PATH = \"./models/DAVIS_bestCI_model_reg1.pth\"  # Replace with the actual path of the trained model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c668246",
   "metadata": {},
   "source": [
    "### 3.2 Model Initialization and Device Configuration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43413642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model configuration  \n",
    "model_config = json.load(open(MODEL_CONFIG_PATH, 'r'))  \n",
    "# Initialize the model  \n",
    "model = TransGNNModel(model_config)  \n",
    "# Check for available GPU  \n",
    "use_cuda = torch.cuda.is_available()  \n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')  \n",
    "model = model.to(device)  \n",
    "\n",
    "# Load trained model weights  \n",
    "try:  \n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=True)  \n",
    "    # Adjust the input dimension of the decoder layer  \n",
    "    model.decoder[0] = nn.Linear(list(checkpoint['decoder.0.weight'].shape)[1], model.decoder[0].out_features).to(device)  \n",
    "    model.load_state_dict(checkpoint)  \n",
    "    print(\"Successfully loaded model state from checkpoint.\")  \n",
    "except Exception as e:  \n",
    "    print(f\"Error loading checkpoint: {e}\")  \n",
    "\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65cee59",
   "metadata": {},
   "source": [
    "### 3.3 Data Preprocessing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence encoding (returns feature vectors and masks)  \n",
    "d_out, mask_d_out = drug_encoder(DRUG_EXAMPLE)  \n",
    "t_out, mask_t_out = target_encoder(PROTEIN_EXAMPLE)  \n",
    "\n",
    "# Convert to tensors and move to device  \n",
    "d_tensor = torch.LongTensor(d_out).unsqueeze(0).to(device)  \n",
    "mask_d_tensor = torch.LongTensor(mask_d_out).unsqueeze(0).to(device)  \n",
    "t_tensor = torch.LongTensor(t_out).unsqueeze(0).to(device)  \n",
    "mask_t_tensor = torch.LongTensor(mask_t_out).unsqueeze(0).to(device)  \n",
    "\n",
    "# Perform prediction  \n",
    "with torch.no_grad():  \n",
    "    prediction = model(d_tensor, t_tensor, mask_d_tensor, mask_t_tensor).cpu().numpy()  \n",
    "\n",
    "print(f\"Predicted Affinity Value: {prediction[0][0]:.4f}\")  # Output formatted to 4 decimal places  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e3920",
   "metadata": {},
   "source": [
    "## IV. Advanced Features  \n",
    "### 4.1 Early Stopping and Email Notification  \n",
    "- **Early Stopping Configuration**: Set `early_stopping_patience` in `config.json` (default: 20 epochs)  \n",
    "- **Email Notification**: Auto-notify upon training completion/failure after enabling email configuration  \n",
    "  ```json  \n",
    "  \"email\": {  \n",
    "    \"enabled\": true,  \n",
    "    \"sender_email\": \"your_email@example.com\",  \n",
    "    \"sender_password\": \"authorization_code\",  \n",
    "    \"receiver_email\": \"recipient@example.com\",  \n",
    "    \"smtp_server\": \"smtp.qq.com\",  # Example for QQ Mail  \n",
    "    \"smtp_port\": 465  \n",
    "  }  \n",
    "  ```  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e2e89",
   "metadata": {},
   "source": [
    "### 4.2 Multi-GPU Training Support  \n",
    "To use multi-GPU training, modify the data loading part in `train_reg.py`:  \n",
    "```python  \n",
    "# Add DistributedDataParallel support (example)  \n",
    "if torch.cuda.device_count() > 1:  \n",
    "    model = torch.nn.DataParallel(model)  \n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eabc90",
   "metadata": {},
   "source": [
    "## V. Citation Suggestions  \n",
    "If using this model for research, please cite it in your paper  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
